{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a code able to read several books in .pdf format and calculate the amount of unique words and their frequencies by language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      words  freq\n",
      "0                   ﻿hamlet     1\n",
      "1                            3613\n",
      "2                     drama     8\n",
      "3                        em   237\n",
      "4                     cinco     5\n",
      "5                     actos    14\n",
      "6                   william     2\n",
      "7               shakespeare     2\n",
      "8                    hamlet   495\n",
      "9                 traducção     1\n",
      "10               portugueza     1\n",
      "11                  segunda     6\n",
      "12                   edição     1\n",
      "13                   lisboa     1\n",
      "14                 imprensa     1\n",
      "15                 nacional     1\n",
      "16           interlocutores     1\n",
      "17               claudiorei     1\n",
      "18                       de   752\n",
      "19                dinamarca    29\n",
      "20              hamletfilho     1\n",
      "21                       do   302\n",
      "22                  defunto     5\n",
      "23                      rei   239\n",
      "24                        e   888\n",
      "25                 sobrinho     7\n",
      "26                 reinante     1\n",
      "27         poloniocamareiro     1\n",
      "28                      mór     1\n",
      "29             horacioamigo     1\n",
      "...                     ...   ...\n",
      "7170                 credit     1\n",
      "7171                   card     1\n",
      "7172  http//pglaforg/donate     1\n",
      "7173              professor     1\n",
      "7174             originator     1\n",
      "7175                library     1\n",
      "7176                  could     1\n",
      "7177                 shared     1\n",
      "7178                 thirty     1\n",
      "7179                  years     1\n",
      "7180                  loose     1\n",
      "7181                network     1\n",
      "7182              volunteer     1\n",
      "7183                  often     1\n",
      "7184                several     1\n",
      "7185              confirmed     1\n",
      "7186                   thus     1\n",
      "7187            necessarily     1\n",
      "7188                  paper     1\n",
      "7189                edition     1\n",
      "7190                   main     1\n",
      "7191                     pg     1\n",
      "7192                 search     1\n",
      "7193               facility     1\n",
      "7194  http//wwwgutenbergorg     1\n",
      "7195               includes     1\n",
      "7196                produce     1\n",
      "7197              subscribe     1\n",
      "7198             newsletter     1\n",
      "7199                   hear     1\n",
      "\n",
      "[7200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "book_dir = './Books'   # makes reference to the folder with all the files\n",
    "\n",
    "#create an empty Dataframe and an index counter to add new entries\n",
    "count_result = pd.DataFrame(columns=['words', 'lang', 'author', 'book', 'freq'])\n",
    "new_entry_index = 0\n",
    "\n",
    "# iterate and read every file by language, author, and title\n",
    "for language in os.listdir(book_dir):\n",
    "    for author in os.listdir(book_dir + '/' + language):\n",
    "        for title in os.listdir(book_dir + '/' + language + '/' + author):\n",
    "            \n",
    "            # this is the final resulting path...\n",
    "            title_path = book_dir + '/' + language + '/' + author + '/' + title\n",
    "            \n",
    "            # now it will read every file\n",
    "            with open(title_path, 'r', encoding='utf8') as current_file:\n",
    "                text = current_file.read()\n",
    "                \n",
    "                # the following lines clean the document's content\n",
    "                text = text.replace('\\n', ' ').replace('\\r', ' ') # remove the backspaces\n",
    "                text = text.lower()    # turn every letter into lower case\n",
    "                skip_list = [',', '.', ':', ';', '?', '!', '\"', \"'\", \"-\", \"(\", \")\", \"{\", \"}\",\n",
    "                            '1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "                for ch in skip_list:\n",
    "                    text = text.replace(ch, '')\n",
    "                \n",
    "                #create a temporary dataframe to store the stats collected by every book title\n",
    "                temp_df = pd.DataFrame(columns=['words', 'lang', 'author', 'book', 'freq'])\n",
    "                for word in text.split(' '):\n",
    "                    if word in temp_df:\n",
    "                        temp_df.loc[temp_df.words == word, 'freq'] += 1\n",
    "                    else:\n",
    "                        new_item = pd.DataFrame({'words':word, 'lang':language, 'author':author,\n",
    "                                                 'book':title, 'freq':1}, index=[new_entry_index])\n",
    "                        temp_df = pd.concat([temp_df, new_item], axis=0, ignore_index=True)\n",
    "                        #temp_df[new_entry_index] = {'words':word, 'lang':language, 'author':author, 'book':title, 'freq':1}\n",
    "                        new_entry_index += 1\n",
    "                new_entry_index = 0\n",
    "            \n",
    "            # this will gather the information accumulated and store it in my final table\n",
    "            count_result = pd.concat([count_result, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "print(count_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
