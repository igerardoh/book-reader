{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will create a code able to read several books in .pdf format and calculate the amount of unique words and their frequencies by language."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      words  freq\n",
      "0                   ﻿hamlet     1\n",
      "1                            3613\n",
      "2                     drama     8\n",
      "3                        em   237\n",
      "4                     cinco     5\n",
      "5                     actos    14\n",
      "6                   william     2\n",
      "7               shakespeare     2\n",
      "8                    hamlet   495\n",
      "9                 traducção     1\n",
      "10               portugueza     1\n",
      "11                  segunda     6\n",
      "12                   edição     1\n",
      "13                   lisboa     1\n",
      "14                 imprensa     1\n",
      "15                 nacional     1\n",
      "16           interlocutores     1\n",
      "17               claudiorei     1\n",
      "18                       de   752\n",
      "19                dinamarca    29\n",
      "20              hamletfilho     1\n",
      "21                       do   302\n",
      "22                  defunto     5\n",
      "23                      rei   239\n",
      "24                        e   888\n",
      "25                 sobrinho     7\n",
      "26                 reinante     1\n",
      "27         poloniocamareiro     1\n",
      "28                      mór     1\n",
      "29             horacioamigo     1\n",
      "...                     ...   ...\n",
      "7170                 credit     1\n",
      "7171                   card     1\n",
      "7172  http//pglaforg/donate     1\n",
      "7173              professor     1\n",
      "7174             originator     1\n",
      "7175                library     1\n",
      "7176                  could     1\n",
      "7177                 shared     1\n",
      "7178                 thirty     1\n",
      "7179                  years     1\n",
      "7180                  loose     1\n",
      "7181                network     1\n",
      "7182              volunteer     1\n",
      "7183                  often     1\n",
      "7184                several     1\n",
      "7185              confirmed     1\n",
      "7186                   thus     1\n",
      "7187            necessarily     1\n",
      "7188                  paper     1\n",
      "7189                edition     1\n",
      "7190                   main     1\n",
      "7191                     pg     1\n",
      "7192                 search     1\n",
      "7193               facility     1\n",
      "7194  http//wwwgutenbergorg     1\n",
      "7195               includes     1\n",
      "7196                produce     1\n",
      "7197              subscribe     1\n",
      "7198             newsletter     1\n",
      "7199                   hear     1\n",
      "\n",
      "[7200 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# specify the folder's directory where the book files are located\n",
    "book_dir = './Books'\n",
    "\n",
    "# create two empty Dataframes to later store the info collected from every file\n",
    "count_result = pd.DataFrame(columns=['lang', 'author', 'book_title', 'words', 'freq'])\n",
    "stat_result = pd.DataFrame(columns=['lang', 'author', 'book_title', 'uniq_words', 'total_words'])\n",
    "\n",
    "# iterate and read every file by language, author, and title\n",
    "for language in os.listdir(book_dir):\n",
    "    for author in os.listdir(book_dir + '/' + language):\n",
    "        for title in os.listdir(book_dir + '/' + language + '/' + author):\n",
    "            \n",
    "            # this is the resulting path...\n",
    "            title_path = book_dir + '/' + language + '/' + author + '/' + title\n",
    "            \n",
    "            # now it will read on every file\n",
    "            with open(title_path, 'r', encoding='utf8') as current_file:\n",
    "                text = current_file.read()\n",
    "                \n",
    "                # the following lines clean the book's content for the further analysis\n",
    "                text = text.replace('\\n', ' ').replace('\\r', ' ') # remove the backspaces\n",
    "                text = text.lower()    # turn every letter into lower case\n",
    "                \n",
    "                # remove the most common symbols, marks, and numbers\n",
    "                skip_list = [',', '.', ':', ';', '¿', '?', '¡', '!', '#' '\"', \"'\", '-', '(', ')', '{', '}',\n",
    "                            '1', '2', '3', '4', '5', '6', '7', '8', '9', '0']\n",
    "                for ch in skip_list:\n",
    "                    text = text.replace(ch, '')\n",
    "                \n",
    "                # create a temporary dataframe for every book title to store and isolate the stats collected\n",
    "                temp_df = pd.DataFrame(columns=['lang', 'author', 'book_title', 'words', 'freq'])\n",
    "                \n",
    "                # this loop will count the frequency for every unique word\n",
    "                for word in text.split(' '):\n",
    "                    if word in temp_df['words'].values:\n",
    "                        temp_df.loc[temp_df.words == word, 'freq'] += 1\n",
    "                    else:\n",
    "                        temp_df.loc[len(temp_df)] = language, author, title.replace('.txt', ''), word, 1\n",
    "                \n",
    "                temp_df = temp_df.drop(temp_df.index[0]) # remove the counted empty spaces\n",
    "                temp_df = temp_df.sort_values('freq', ascending=False) # sort the dataframe in descending order\n",
    "                \n",
    "                # collect the data from the current file before moving to the next one\n",
    "                stat_result.loc[len(stat_result)] = language, author, title.replace('.txt', ''), len(temp_df), sum(temp_df['freq'].values)\n",
    "            \n",
    "            # this will save and accumulate the info collected from the temporary dataframe into a different table\n",
    "            count_result = pd.concat([count_result, temp_df], axis=0, ignore_index=True)\n",
    "\n",
    "print('\\n-----------------------------')\n",
    "print(stat_result)\n",
    "print('\\n-----------------------------')\n",
    "print(count_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
